{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Best_model_with_attention.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install wandb"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kVtFDX1WuBLo",
        "outputId": "0631ff47-780c-4464-c363-daf2a5cc9885"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting wandb\n",
            "  Downloading wandb-0.12.16-py2.py3-none-any.whl (1.8 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.8 MB 4.2 MB/s \n",
            "\u001b[?25hRequirement already satisfied: psutil>=5.0.0 in /usr/local/lib/python3.7/dist-packages (from wandb) (5.4.8)\n",
            "Collecting sentry-sdk>=1.0.0\n",
            "  Downloading sentry_sdk-1.5.11-py2.py3-none-any.whl (144 kB)\n",
            "\u001b[K     |████████████████████████████████| 144 kB 48.4 MB/s \n",
            "\u001b[?25hCollecting docker-pycreds>=0.4.0\n",
            "  Downloading docker_pycreds-0.4.0-py2.py3-none-any.whl (9.0 kB)\n",
            "Collecting pathtools\n",
            "  Downloading pathtools-0.1.2.tar.gz (11 kB)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from wandb) (57.4.0)\n",
            "Requirement already satisfied: protobuf>=3.12.0 in /usr/local/lib/python3.7/dist-packages (from wandb) (3.17.3)\n",
            "Collecting GitPython>=1.0.0\n",
            "  Downloading GitPython-3.1.27-py3-none-any.whl (181 kB)\n",
            "\u001b[K     |████████████████████████████████| 181 kB 49.8 MB/s \n",
            "\u001b[?25hRequirement already satisfied: python-dateutil>=2.6.1 in /usr/local/lib/python3.7/dist-packages (from wandb) (2.8.2)\n",
            "Requirement already satisfied: requests<3,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from wandb) (2.23.0)\n",
            "Collecting shortuuid>=0.5.0\n",
            "  Downloading shortuuid-1.0.8-py3-none-any.whl (9.5 kB)\n",
            "Requirement already satisfied: PyYAML in /usr/local/lib/python3.7/dist-packages (from wandb) (3.13)\n",
            "Requirement already satisfied: Click!=8.0.0,>=7.0 in /usr/local/lib/python3.7/dist-packages (from wandb) (7.1.2)\n",
            "Requirement already satisfied: six>=1.13.0 in /usr/local/lib/python3.7/dist-packages (from wandb) (1.15.0)\n",
            "Collecting setproctitle\n",
            "  Downloading setproctitle-1.2.3-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (29 kB)\n",
            "Requirement already satisfied: promise<3,>=2.0 in /usr/local/lib/python3.7/dist-packages (from wandb) (2.3)\n",
            "Collecting gitdb<5,>=4.0.1\n",
            "  Downloading gitdb-4.0.9-py3-none-any.whl (63 kB)\n",
            "\u001b[K     |████████████████████████████████| 63 kB 1.7 MB/s \n",
            "\u001b[?25hRequirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.7/dist-packages (from GitPython>=1.0.0->wandb) (4.2.0)\n",
            "Collecting smmap<6,>=3.0.1\n",
            "  Downloading smmap-5.0.0-py3-none-any.whl (24 kB)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.0.0->wandb) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.0.0->wandb) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.0.0->wandb) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.0.0->wandb) (2021.10.8)\n",
            "Building wheels for collected packages: pathtools\n",
            "  Building wheel for pathtools (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pathtools: filename=pathtools-0.1.2-py3-none-any.whl size=8806 sha256=f1a7a909c1ee02af3b7dbc3d6aa373a78979d79ef91652074b67f0e08a63d583\n",
            "  Stored in directory: /root/.cache/pip/wheels/3e/31/09/fa59cef12cdcfecc627b3d24273699f390e71828921b2cbba2\n",
            "Successfully built pathtools\n",
            "Installing collected packages: smmap, gitdb, shortuuid, setproctitle, sentry-sdk, pathtools, GitPython, docker-pycreds, wandb\n",
            "Successfully installed GitPython-3.1.27 docker-pycreds-0.4.0 gitdb-4.0.9 pathtools-0.1.2 sentry-sdk-1.5.11 setproctitle-1.2.3 shortuuid-1.0.8 smmap-5.0.0 wandb-0.12.16\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "h_kxOA83S4Z2"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "from matplotlib.font_manager import FontProperties\n",
        "import wandb\n",
        "from tensorflow.keras.layers import Layer\n",
        "from tensorflow.keras import backend as K\n",
        "\n",
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%capture\n",
        "!wget https://storage.googleapis.com/gresearch/dakshina/dakshina_dataset_v1.0.tar \n",
        "!tar -xvf  'dakshina_dataset_v1.0.tar'\n"
      ],
      "metadata": {
        "id": "Sg42k_XjS9xn"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#standardising the dataset\n",
        "def opening_data(data_path):\n",
        "  with open(data_path) as d:\n",
        "      content = d.readlines()\n",
        "  sets =[] \n",
        "  for line in content:\n",
        "    datset = line.split(\"\\t\")\n",
        "    sets.append(datset)\n",
        "  dictionary = dict([(data[1], data[0]) for data in sets])\n",
        "  return dictionary\n",
        "  \n",
        "train_dict = opening_data(\"/content/dakshina_dataset_v1.0/ta/lexicons/ta.translit.sampled.train.tsv\")\n",
        "val_dict =   opening_data(\"/content/dakshina_dataset_v1.0/ta/lexicons/ta.translit.sampled.dev.tsv\")\n",
        "test_dict = opening_data(\"/content/dakshina_dataset_v1.0/ta/lexicons/ta.translit.sampled.test.tsv\")"
      ],
      "metadata": {
        "id": "6kaAUqVfTAB3"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#number of training set\n",
        "num_train = len(train_dict.keys())\n",
        "num_test = len(test_dict.keys())\n",
        "num_val = len(val_dict.keys())\n"
      ],
      "metadata": {
        "id": "QFywYI6oSm4u"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Data preprocessing to build the rnn model\n",
        "def data_preprocess(diction):\n",
        "    input_texts = []\n",
        "    target_texts = []\n",
        "    input_characters = []\n",
        "    target_characters = []\n",
        "\n",
        "    for key in diction:\n",
        "        # Store the word in the source language\n",
        "        input_texts.append(key)\n",
        "        # Store the word in the target language\n",
        "        target_texts.append(\"\\t\"+diction[key]+\"\\n\")\n",
        "        # Add the characters to the respective character lists\n",
        "        input_characters = list(set(input_characters + list(key)))\n",
        "        target_characters = list(set(target_characters + list(diction[key])))\n",
        "\n",
        "    # Sort the input characters\n",
        "    input_characters = sorted(list(set(input_characters)))\n",
        "    # Sort the target characters\n",
        "    target_characters = target_characters + [\"\\t\", \"\\n\"]\n",
        "    target_characters = sorted(list(set(target_characters)))\n",
        "\n",
        "    # Number of unique tokens in the source language\n",
        "    num_encoder_tokens = len(input_characters)+1\n",
        "    # Number of unique tokens in the target language\n",
        "    num_decoder_tokens = len(target_characters)+1\n",
        "\n",
        "    # Max input word length\n",
        "    max_encoder_seq_length = max([len(txt) for txt in input_texts]) \n",
        "    # Max output word length\n",
        "    max_decoder_seq_length = max([len(txt) for txt in target_texts])\n",
        "    # Map characters to numerical indices (using +1 to avoid any character being mapped to 0)\n",
        "    input_char_index = dict([(ch, i + 1) for i, ch in enumerate(input_characters)])\n",
        "    target_char_index = dict([(ch, i + 1) for i, ch in enumerate(target_characters)])\n",
        "\n",
        "    return input_characters, target_characters, num_encoder_tokens, num_decoder_tokens, max_encoder_seq_length, max_decoder_seq_length, input_char_index, target_char_index\n",
        "\n",
        "def one_hot_coding(diction, max_encoder_seq_length, max_decoder_seq_length, num_encoder_tokens, num_decoder_tokens):\n",
        "    \"\"\"\n",
        "    This function takes the training/validation/test dictionary as input and produces\n",
        "    the one-hot encoded versions of the respective data.\n",
        "    \"\"\"\n",
        "    input_texts = []\n",
        "    target_texts = []\n",
        "\n",
        "    for key in diction:\n",
        "        # Store the word in the source language\n",
        "        input_texts.append(key)\n",
        "        # Store the word in the target language\n",
        "        target_texts.append(\"\\t\"+diction[key]+\"\\n\")\n",
        "\n",
        "    K = len(diction.keys())\n",
        "    encoder_input_data = np.zeros((K, max_encoder_seq_length, num_encoder_tokens), dtype=\"float\")\n",
        "    decoder_input_data = np.zeros((K, max_decoder_seq_length, num_decoder_tokens), dtype=\"float\")\n",
        "    decoder_output_data = np.zeros((K, max_decoder_seq_length, num_decoder_tokens), dtype=\"float\")\n",
        "\n",
        "    for i in range(K):\n",
        "        source_texts = input_texts[i]\n",
        "        target_text = target_texts[i]\n",
        "\n",
        "        # One-hot encoding for the input\n",
        "        for j, ch in enumerate(source_texts):\n",
        "            encoder_input_data[i, j, input_char_index[ch]] = 1.0\n",
        "\n",
        "        # One-hot encoding for the output\n",
        "        for j, ch in enumerate(target_text):\n",
        "            decoder_input_data[i, j, target_char_index[ch]]= 1.0\n",
        "            if j >= 1:\n",
        "                # The decoder output is one step ahead of the decoder input\n",
        "                decoder_output_data[i, j-1, target_char_index[ch]] = 1.0\n",
        "\n",
        "    \n",
        "\n",
        "    return input_texts, target_texts, encoder_input_data, decoder_input_data, decoder_output_data\n"
      ],
      "metadata": {
        "id": "TUT-cCiATCdQ"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "input_characters, target_characters, num_encoder_tokens, num_decoder_tokens, max_encoder_seq_length, max_decoder_seq_length, input_char_index, target_char_index = data_preprocess(train_dict)\n",
        "input_words, target_words, encoder_input_data, decoder_input_data, decoder_output_data = one_hot_coding(train_dict, max_encoder_seq_length, max_decoder_seq_length, num_encoder_tokens, num_decoder_tokens)\n",
        "val_input_words, val_target_words, val_encoder_input_data, val_decoder_input_data, val_decoder_output_data = one_hot_coding(val_dict, max_encoder_seq_length, max_decoder_seq_length, num_encoder_tokens, num_decoder_tokens)\n",
        "test_input_words, test_target_words, test_encoder_input_data, test_decoder_input_data, test_decoder_output_data = one_hot_coding(test_dict, max_encoder_seq_length, max_decoder_seq_length, num_encoder_tokens, num_decoder_tokens)"
      ],
      "metadata": {
        "id": "zR3pKk0zTGhZ"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Dictionaries mapping from indices to characters\n",
        "reverse_input_char_index = dict((i, char) for char, i in input_char_index.items())\n",
        "reverse_target_char_index = dict((i, char) for char, i in target_char_index.items())\n",
        "reverse_target_char_index[0] = \"\\n\""
      ],
      "metadata": {
        "id": "dEvKDodcSwHp"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Using label encoding for the encoder inputs (and then find an embedding using the Embedding layer)\n",
        "encoder_input_data = np.argmax(encoder_input_data, axis=2)\n",
        "val_encoder_input_data = np.argmax(val_encoder_input_data, axis=2)\n",
        "test_encoder_input_data = np.argmax(test_encoder_input_data, axis=2)\n",
        "\n",
        "decoder_input_data = np.argmax(decoder_input_data, axis=2)\n",
        "val_decoder_input_data = np.argmax(val_decoder_input_data, axis=2)\n",
        "test_decoder_input_data = np.argmax(test_decoder_input_data, axis=2)\n"
      ],
      "metadata": {
        "id": "SwfNIGf_TPBA"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class AttentionLayer(Layer):\n",
        "    \"\"\"\n",
        "    This class implements Bahdanau attention (https://arxiv.org/pdf/1409.0473.pdf).\n",
        "    There are three sets of weights introduced W_a, U_a, and V_a\n",
        "     \"\"\"\n",
        "\n",
        "    def __init__(self, **kwargs):\n",
        "        super(AttentionLayer, self).__init__(**kwargs)\n",
        "\n",
        "    def build(self, input_shape):\n",
        "        assert isinstance(input_shape, list)\n",
        "        # Create a trainable weight variable for this layer.\n",
        "\n",
        "        self.W_a = self.add_weight(name='W_a',\n",
        "                                   shape=tf.TensorShape((input_shape[0][2], input_shape[0][2])),\n",
        "                                   initializer='uniform',\n",
        "                                   trainable=True)\n",
        "        self.U_a = self.add_weight(name='U_a',\n",
        "                                   shape=tf.TensorShape((input_shape[1][2], input_shape[0][2])),\n",
        "                                   initializer='uniform',\n",
        "                                   trainable=True)\n",
        "        self.V_a = self.add_weight(name='V_a',\n",
        "                                   shape=tf.TensorShape((input_shape[0][2], 1)),\n",
        "                                   initializer='uniform',\n",
        "                                   trainable=True)\n",
        "\n",
        "        super(AttentionLayer, self).build(input_shape)  # Be sure to call this at the end\n",
        "\n",
        "    def call(self, inputs, verbose=False):\n",
        "        \"\"\"\n",
        "        inputs: [encoder_output_sequence, decoder_output_sequence]\n",
        "        \"\"\"\n",
        "        assert type(inputs) == list\n",
        "        encoder_out_seq, decoder_out_seq = inputs\n",
        "        if verbose:\n",
        "            print('encoder_out_seq>', encoder_out_seq.shape)\n",
        "            print('decoder_out_seq>', decoder_out_seq.shape)\n",
        "\n",
        "        def energy_step(inputs, states):\n",
        "            \"\"\" Step function for computing energy for a single decoder state\n",
        "            inputs: (batchsize * 1 * de_in_dim)\n",
        "            states: (batchsize * 1 * de_latent_dim)\n",
        "            \"\"\"\n",
        "\n",
        "            assert_msg = \"States must be an iterable. Got {} of type {}\".format(states, type(states))\n",
        "            assert isinstance(states, list) or isinstance(states, tuple), assert_msg\n",
        "\n",
        "            \"\"\" Some parameters required for shaping tensors\"\"\"\n",
        "            en_seq_len, en_hidden = encoder_out_seq.shape[1], encoder_out_seq.shape[2]\n",
        "            de_hidden = inputs.shape[-1]\n",
        "\n",
        "            \"\"\" Computing S.Wa where S=[s0, s1, ..., si]\"\"\"\n",
        "            # <= batch size * en_seq_len * latent_dim\n",
        "            W_a_dot_s = K.dot(encoder_out_seq, self.W_a)\n",
        "\n",
        "            \"\"\" Computing hj.Ua \"\"\"\n",
        "            U_a_dot_h = K.expand_dims(K.dot(inputs, self.U_a), 1)  # <= batch_size, 1, latent_dim\n",
        "            if verbose:\n",
        "                print('Ua.h>', U_a_dot_h.shape)\n",
        "\n",
        "            \"\"\" tanh(S.Wa + hj.Ua) \"\"\"\n",
        "            # <= batch_size*en_seq_len, latent_dim\n",
        "            Ws_plus_Uh = K.tanh(W_a_dot_s + U_a_dot_h)\n",
        "            if verbose:\n",
        "                print('Ws+Uh>', Ws_plus_Uh.shape)\n",
        "\n",
        "            \"\"\" softmax(va.tanh(S.Wa + hj.Ua)) \"\"\"\n",
        "            # <= batch_size, en_seq_len\n",
        "            e_i = K.squeeze(K.dot(Ws_plus_Uh, self.V_a), axis=-1)\n",
        "            # <= batch_size, en_seq_len\n",
        "            e_i = K.softmax(e_i)\n",
        "\n",
        "            if verbose:\n",
        "                print('ei>', e_i.shape)\n",
        "\n",
        "            return e_i, [e_i]\n",
        "\n",
        "        def context_step(inputs, states):\n",
        "            \"\"\" Step function for computing ci using ei \"\"\"\n",
        "\n",
        "            assert_msg = \"States must be an iterable. Got {} of type {}\".format(states, type(states))\n",
        "            assert isinstance(states, list) or isinstance(states, tuple), assert_msg\n",
        "\n",
        "            # <= batch_size, hidden_size\n",
        "            c_i = K.sum(encoder_out_seq * K.expand_dims(inputs, -1), axis=1)\n",
        "            if verbose:\n",
        "                print('ci>', c_i.shape)\n",
        "            return c_i, [c_i]\n",
        "\n",
        "        fake_state_c = K.sum(encoder_out_seq, axis=1)\n",
        "        fake_state_e = K.sum(encoder_out_seq, axis=2)  # <= (batch_size, enc_seq_len, latent_dim\n",
        "\n",
        "        \"\"\" Computing energy outputs \"\"\"\n",
        "        # e_outputs => (batch_size, de_seq_len, en_seq_len)\n",
        "        last_out, e_outputs, _ = K.rnn(\n",
        "            energy_step, decoder_out_seq, [fake_state_e],\n",
        "        )\n",
        "\n",
        "        \"\"\" Computing context vectors \"\"\"\n",
        "        last_out, c_outputs, _ = K.rnn(\n",
        "            context_step, e_outputs, [fake_state_c],\n",
        "        )\n",
        "\n",
        "        return c_outputs, e_outputs\n",
        "\n",
        "    def compute_output_shape(self, input_shape):\n",
        "        \"\"\" Outputs produced by the layer \"\"\"\n",
        "        return [\n",
        "            tf.TensorShape((input_shape[1][0], input_shape[1][1], input_shape[1][2])),\n",
        "            tf.TensorShape((input_shape[1][0], input_shape[1][1], input_shape[0][1]))\n",
        "        ]\n"
      ],
      "metadata": {
        "id": "Ho3wxPN_TRbv"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def build_model(latent_dim, rnn_type, embedding_dim, dropout):\n",
        "   \n",
        "    # ENCODER\n",
        "    encoder_input = keras.Input(shape=(None, ), name=\"EncoderInput\")\n",
        "    encoder_embedding = keras.layers.Embedding(num_encoder_tokens, embedding_dim, name=\"EncoderInputEmbedding\", mask_zero=True)(encoder_input)\n",
        "\n",
        "    if rnn_type == 'LSTM':\n",
        "        encoder_lstm = tf.keras.layers.LSTM(latent_dim,return_sequences=True,return_state=True,name=\"EncoderLayer\" ,dropout=dropout,recurrent_dropout=dropout)\n",
        "        encoder_output, state_h, state_c = encoder_lstm(encoder_embedding)\n",
        "    if rnn_type == 'GRU':\n",
        "        encoder_gru = tf.keras.layers.GRU(latent_dim,return_sequences=True,return_state=True,name=\"EncoderLayer\" ,dropout=dropout,recurrent_dropout=dropout)\n",
        "        encoder_output, gru_state = encoder_gru(encoder_embedding)\n",
        "    if rnn_type == 'RNN':\n",
        "        encoder_rnn = tf.keras.layers.SimpleRNN(latent_dim,return_sequences=True,return_state=True,name=\"EncoderLayer\" ,dropout=dropout,recurrent_dropout=dropout)\n",
        "        encoder_output, rnn_state = encoder_rnn(encoder_embedding)   \n",
        "\n",
        "    ## DECODER\n",
        "    decoder_input = keras.Input(shape=(None, ), name=\"DecoderInput\")\n",
        "    dec_emb = keras.layers.Embedding(num_decoder_tokens , 64, name=\"DecoderInputEmbedding\", mask_zero=True)(decoder_input)\n",
        "\n",
        "    if rnn_type == 'LSTM':\n",
        "        decoder_lstm = tf.keras.layers.LSTM(latent_dim, return_sequences=True, return_state=True, name=\"DecoderLayer\" ,dropout=dropout,recurrent_dropout=dropout )\n",
        "        decoder_output,decoder_fwd_state, decoder_back_state = decoder_lstm(dec_emb,initial_state=[state_h, state_c])\n",
        "    if rnn_type == 'GRU':\n",
        "        decoder_gru = tf.keras.layers.GRU(latent_dim,return_sequences=True,return_state=True,name=\"DecoderLayer\" ,dropout=dropout,recurrent_dropout=dropout)\n",
        "        decoder_output, decoder_state_gru = decoder_gru(dec_emb,initial_state = gru_state)\n",
        "    if rnn_type =='RNN':\n",
        "        decoder_rnn = tf.keras.layers.SimpleRNN(latent_dim,return_sequences=True,return_state=True,name=\"DecoderLayer\" ,dropout=dropout,recurrent_dropout=dropout)\n",
        "        decoder_output, decoder_state_rnn = decoder_rnn(dec_emb,initial_state = rnn_state)\n",
        "\n",
        "    # Attention layer\n",
        "    attn_out, attn_states = AttentionLayer(name='attention_layer')([encoder_output, decoder_output])\n",
        "\n",
        "\n",
        "    # Concat attention input and decoder LSTM output\n",
        "    decoder_concat_input = tf.keras.layers.Concatenate(axis=-1, name='concat_layer')([decoder_output, attn_out])\n",
        "\n",
        "    #dense layer\n",
        "    decoder_dense =  tf.keras.layers.TimeDistributed(keras.layers.Dense(num_decoder_tokens, activation='softmax'))\n",
        "    decoder_outputs = decoder_dense(decoder_concat_input)\n",
        "\n",
        "    # Define the model \n",
        "    model = keras.Model([encoder_input, decoder_input], decoder_outputs)\n",
        "\n",
        "    return model\n"
      ],
      "metadata": {
        "id": "xrTZpBR4TT1v"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def build_inference_model(model,rnn_type, latent_dim):\n",
        "  if rnn_type == \"LSTM\":\n",
        "              # Input to the encoder\n",
        "              encoder_inputs = model.input[0]\n",
        "\n",
        "              # Output of the encoder\n",
        "              encoder_outputs, state_h_enc, state_c_enc = model.layers[4].output\n",
        "              encoder_states = [encoder_outputs,state_h_enc, state_c_enc]\n",
        "\n",
        "              # Create an encoder model \n",
        "              encoder_model = keras.Model(encoder_inputs, encoder_states)\n",
        "\n",
        "\n",
        "              # Input to the decoder\n",
        "\n",
        "              decoder_state_input_h = keras.Input(shape=(latent_dim,))\n",
        "              decoder_state_input_c = keras.Input(shape=(latent_dim,))\n",
        "              decoder_hidden_state_inputs = keras.Input(shape=(None,latent_dim))\n",
        "              decoder_states_inputs = [decoder_state_input_h, decoder_state_input_c]\n",
        "\n",
        "              decoder_inputs = model.layers[1].output\n",
        "              decoder_embedding_layer = model.layers[3]\n",
        "              decoder_embedding = decoder_embedding_layer(decoder_inputs)\n",
        "\n",
        "              decoder_lstm = model.layers[5]\n",
        "\n",
        "              decoder_outputs, state_h_dec, state_c_dec = decoder_lstm(decoder_embedding, initial_state=decoder_states_inputs)\n",
        "              decoder_states = [state_h_dec, state_c_dec]\n",
        "\n",
        "              #attention\n",
        "              attn_layer = model.layers[6]\n",
        "              attn_out_inf, attn_states_inf = attn_layer([decoder_hidden_state_inputs,decoder_outputs])\n",
        "\n",
        "              #concat\n",
        "              concate = model.layers[7]\n",
        "              decoder_inf_concat = concate([decoder_outputs,attn_out_inf])\n",
        "\n",
        "              # Softmax layer\n",
        "              decoder_dense = model.layers[8]\n",
        "              decoder_outputs = decoder_dense(decoder_inf_concat)\n",
        "\n",
        "              # Create the decoder model\n",
        "              decoder_model = keras.Model([decoder_inputs] + [decoder_hidden_state_inputs,decoder_state_input_h,decoder_state_input_c], [decoder_outputs] + decoder_states +[attn_states_inf])\n",
        "\n",
        "\n",
        "  else:\n",
        "              # Input to the encoder\n",
        "              encoder_inputs = model.input[0]\n",
        "\n",
        "              # Output of the encoder\n",
        "              encoder_outputs, state_gru_enc = model.layers[4].output\n",
        "              encoder_states = [encoder_outputs,state_gru_enc]\n",
        "\n",
        "              # Create an encoder model \n",
        "              encoder_model = keras.Model(encoder_inputs, encoder_states)\n",
        "\n",
        "              # Input to the decoder\n",
        "\n",
        "              decoder_state_input = keras.Input(shape=(latent_dim,))\n",
        "              decoder_hidden_state_inputs = keras.Input(shape=(None,latent_dim))\n",
        "              decoder_states_inputs = [decoder_state_input]\n",
        "\n",
        "              decoder_inputs = model.layers[1].output\n",
        "              decoder_embedding_layer = model.layers[3]\n",
        "              decoder_embedding = decoder_embedding_layer(decoder_inputs)\n",
        "\n",
        "              decoder_gru = model.layers[5]\n",
        "\n",
        "              decoder_outputs, state_gru_dec = decoder_gru(decoder_embedding, initial_state=decoder_states_inputs)\n",
        "              decoder_states = [state_gru_dec]\n",
        "\n",
        "\n",
        "              #attention\n",
        "              attn_layer = model.layers[6]\n",
        "              attn_out_inf, attn_states_inf = attn_layer([decoder_hidden_state_inputs,decoder_outputs])\n",
        "\n",
        "              #concat\n",
        "              concate = model.layers[7]\n",
        "              decoder_inf_concat = concate([decoder_outputs,attn_out_inf])\n",
        "\n",
        "              # Softmax layer\n",
        "              decoder_dense = model.layers[8]\n",
        "              decoder_outputs = decoder_dense(decoder_inf_concat)\n",
        "\n",
        "              # Create the decoder model\n",
        "              decoder_model = keras.Model([decoder_inputs] + [decoder_hidden_state_inputs,decoder_state_input], [decoder_outputs] + decoder_states +[attn_states_inf])\n",
        "\n",
        "  return encoder_model, decoder_model\n"
      ],
      "metadata": {
        "id": "jL3pHkeZ-YtG"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train():\n",
        "\n",
        "   \n",
        "\n",
        "    # Define the model\n",
        "    model = build_model(256, \"GRU\", 258, 0.3)\n",
        "\n",
        "    # Compile the model\n",
        "    model.compile(optimizer=\"adam\", loss=\"categorical_crossentropy\", metrics=[\"accuracy\"])\n",
        "\n",
        "    # Train the model\n",
        "    history = model.fit(\n",
        "            [encoder_input_data, decoder_input_data],\n",
        "            decoder_output_data,\n",
        "            batch_size = 64,\n",
        "            epochs = 10,\n",
        "            verbose = 2)\n",
        "    return model\n",
        "   "
      ],
      "metadata": {
        "id": "Zz8MVa18TYVj"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = train()"
      ],
      "metadata": {
        "id": "ZWmfEOcgTdB1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "01afd63f-3655-4e89-b387-d629ca09e097"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "WARNING:tensorflow:Layer EncoderLayer will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
            "WARNING:tensorflow:Layer DecoderLayer will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
            "Epoch 1/10\n",
            "1036/1036 - 484s - loss: 0.3017 - accuracy: 0.6935 - 484s/epoch - 467ms/step\n",
            "Epoch 2/10\n",
            "1036/1036 - 470s - loss: 0.1228 - accuracy: 0.8221 - 470s/epoch - 454ms/step\n",
            "Epoch 3/10\n",
            "1036/1036 - 466s - loss: 0.1023 - accuracy: 0.8361 - 466s/epoch - 450ms/step\n",
            "Epoch 4/10\n",
            "1036/1036 - 467s - loss: 0.0894 - accuracy: 0.8446 - 467s/epoch - 451ms/step\n",
            "Epoch 5/10\n",
            "1036/1036 - 466s - loss: 0.0801 - accuracy: 0.8511 - 466s/epoch - 450ms/step\n",
            "Epoch 6/10\n",
            "1036/1036 - 461s - loss: 0.0727 - accuracy: 0.8564 - 461s/epoch - 445ms/step\n",
            "Epoch 7/10\n",
            "1036/1036 - 459s - loss: 0.0671 - accuracy: 0.8602 - 459s/epoch - 443ms/step\n",
            "Epoch 8/10\n",
            "1036/1036 - 461s - loss: 0.0619 - accuracy: 0.8637 - 461s/epoch - 445ms/step\n",
            "Epoch 9/10\n",
            "1036/1036 - 463s - loss: 0.0575 - accuracy: 0.8669 - 463s/epoch - 447ms/step\n",
            "Epoch 10/10\n",
            "1036/1036 - 463s - loss: 0.0546 - accuracy: 0.8687 - 463s/epoch - 447ms/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Get the encoder and decoder model\n",
        "encoder_model, decoder_model = build_inference_model(model,\"GRU\",256)\n",
        "def calculate_accuracy(encoder_model,decoder_model,input_data,target_words):\n",
        "    predicted = []\n",
        "    n = input_data.shape[0]\n",
        "    batch_size = 700\n",
        "    for i in range(0, n, batch_size):\n",
        "        # Inputs\n",
        "        input_words = input_data[i:i+batch_size]\n",
        "        batch_size = input_words.shape[0]\n",
        "        encoded_hidden_cell_states = encoder_model.predict(input_words)\n",
        "\n",
        "        target_sentence = np.zeros((batch_size, 1, num_decoder_tokens))\n",
        "        target_sentence[:, 0, target_char_index[\"\\t\"]] = 1.0\n",
        "        target_sentence = np.argmax(target_sentence, axis=2)\n",
        "\n",
        "        decoded_words = [\"\"]*batch_size\n",
        "        for i in range(max_decoder_seq_length):\n",
        "            output_tokens, state, attn = decoder_model.predict([target_sentence] + [encoded_hidden_cell_states])\n",
        "\n",
        "            sampled_char_index = np.argmax(output_tokens[:, -1, :], axis=1)\n",
        "\n",
        "            target_sentence = np.zeros((batch_size, 1, num_decoder_tokens))\n",
        "\n",
        "            for j, ch_index in enumerate(sampled_char_index):\n",
        "                decoded_words[j] += reverse_target_char_index[ch_index]\n",
        "                target_sentence[j, 0, ch_index] = 1.0\n",
        "\n",
        "            target_sentence = np.argmax(target_sentence, axis=2)\n",
        "\n",
        "            encoded_hidden_cell_states[1] = [state]\n",
        "\n",
        "        decoded_words = [word[:word.find(\"\\n\")] for word in decoded_words]\n",
        "        predicted = predicted + decoded_words\n",
        "        \n",
        "      \n",
        "    actual_words = [word[1:-1] for word in target_words]\n",
        "    # Calculate validation accuracy\n",
        "    accuracy = np.mean(np.array(predicted) == np.array(actual_words))\n",
        "    return accuracy,actual_words,predicted\n"
      ],
      "metadata": {
        "id": "Zzlqk8Fdn_3_"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Validation_accuracy,val_actual_word,val_predicted = calculate_accuracy(encoder_model,decoder_model,val_encoder_input_data,val_target_words)\n",
        "Test_accuracy,test_actual_word,test_predicted = calculate_accuracy(encoder_model,decoder_model,test_encoder_input_data,test_target_words)\n",
        "print(\"Validation_accuracy\",Validation_accuracy * 100)\n",
        "print(\"Test_accuracy\",Test_accuracy*100)"
      ],
      "metadata": {
        "id": "hDa7kvTMVF2j",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "da587a18-2d51-4310-d944-32fe8156beb9"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation_accuracy 57.21422274463709\n",
            "Test_accuracy 55.72954778281868\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "keras.utils.plot_model(model)"
      ],
      "metadata": {
        "id": "QwpkoZ1eQRKN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "wandb.init(entity=\"swe-rana\",project=\"CS6910Assignment3\")\n",
        "wandb.log({\"Test accuracy\" : Test_accuracy})"
      ],
      "metadata": {
        "id": "jz-XoRjzWS8z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data= pd.DataFrame({\"Input Words\":test_input_words,\"Target words\": test_actual_word,\"Predicted_words\": test_predicted})\n",
        "data.to_csv(\"Test_Data_Predictions_with_attention.csv\", index=False)\n"
      ],
      "metadata": {
        "id": "KzzlegWqDxwU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def decode_best_model(input_word,encoder_model,decoder_model):\n",
        "    # Encode the input string\n",
        "    encoded_hidden_cell_states = encoder_model.predict(input_word)\n",
        "\n",
        "    target_sentence = np.zeros((1, 1, num_decoder_tokens))\n",
        "    # Set the first character to \"tab\" as it is the start of sequence character\n",
        "    target_sentence[0, 0, target_char_index[\"\\t\"]] = 1.0\n",
        "    target_sentence = np.argmax(target_sentence, axis=2)\n",
        "    stop = False\n",
        "    decoded_word = \"\"\n",
        "    attention = []\n",
        "    while not stop:\n",
        "        output_tokens, h, attn = decoder_model.predict([target_sentence] + encoded_hidden_cell_states)\n",
        "        attention.append(attn)\n",
        "\n",
        "        sampled_char_index = np.argmax(output_tokens[0, -1, :])\n",
        "\n",
        "        sampled_char = reverse_target_char_index[sampled_char_index]\n",
        "        decoded_word += reverse_target_char_index[sampled_char_index]\n",
        "\n",
        "        if sampled_char == \"\\n\" or len(decoded_word) >= max_decoder_seq_length:\n",
        "            stop = True\n",
        "\n",
        "        # Update the target sequence which goes back as input to the decoder.\n",
        "        target_sentence = np.zeros((1, 1, num_decoder_tokens))\n",
        "        target_sentence[0, 0, sampled_char_index] = 1.0\n",
        "        target_sentence = np.argmax(target_sentence, axis=2)\n",
        "\n",
        "        # Update the hidden state and cell state \n",
        "        encoded_hidden_cell_states[1] = [h]\n",
        "\n",
        "    return decoded_word,attention"
      ],
      "metadata": {
        "id": "982eJ7_XLE-V"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Plotting Heatmaps**"
      ],
      "metadata": {
        "id": "i6A8Nwtt8GVg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "target_word = []\n",
        "input_word = []\n",
        "predicted_word = []\n",
        "\n",
        "random_indices = [np.random.randint(0, num_test) for i in range(9)]\n",
        "\n",
        "fig = plt.figure(figsize=(10,10))\n",
        "\n",
        "index=1\n",
        "att = []\n",
        "for i in random_indices:\n",
        "    inp = test_encoder_input_data[i:i+1]\n",
        "    decoded_word,attention = decode_best_model(inp,encoder_model,decoder_model)\n",
        "\n",
        "    attention = np.array(attention)\n",
        "    plt.subplot(3,3,index)\n",
        "    plt.imshow(attention.reshape(attention.shape[0],attention.shape[-1])[:,:len(decoded_word)],cmap=\"magma\")\n",
        "\n",
        "    plt.yticks(range(attention.shape[0]),decoded_word,fontproperties=FontProperties(fname = '/content/Latha2.ttf'))\n",
        "    plt.xticks(range(attention.shape[0]),test_input_words[i])\n",
        "\n",
        "    input_word.append(test_input_words[i])\n",
        "    predicted_word.append(decoded_word.strip(\"\\n\"))\n",
        "    att.append(attention.reshape(attention.shape[0],attention.shape[-1])[:,:len(decoded_word)])\n",
        "    target_word.append(test_target_words[i][1:-1])\n",
        "    index+=1\n",
        "plt.show()\n",
        "\n",
        "df_train = pd.DataFrame({\"Input\": input_word, \"Target\" : target_word, \"predicted\":predicted_word})\n"
      ],
      "metadata": {
        "id": "rhY6gIeMvPXM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_train.to_csv(\"gif.csv\",index=False)"
      ],
      "metadata": {
        "id": "X24iblQHRWdX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import warnings\n",
        "import cv2 as cv\n",
        "from moviepy.editor import ImageSequenceClip\n",
        "\n",
        "\n",
        "\n",
        "for num in range(9):\n",
        "  text = df_train.iloc[num,2]\n",
        "  sequence =[]\n",
        "\n",
        "  data = df_train.iloc[num,0]\n",
        "  warnings.filterwarnings('ignore')\n",
        "  for i in range(len(text)):\n",
        "    plt.text(0.8,0.8,text,fontproperties=FontProperties(fname = '/content/Latha2.ttf'),fontsize = 30)\n",
        "    plt.text(0.8,0.8,text[i],fontproperties=FontProperties(fname = '/content/Latha2.ttf'),fontsize = 30)\n",
        "    plt.axis('off')\n",
        "\n",
        "    alphas = att[num][i]\n",
        "    for j in range(len(data)):\n",
        "      t=plt.text(0.5*(j/6),0.5,data[j],fontsize=30)\n",
        "      #print(alphas[j])\n",
        "      t.set_bbox(dict(facecolor='blue', alpha=alphas[j], edgecolor='blue'))\n",
        "    plt.savefig('saved_img.png')\n",
        "    plt.show()\n",
        "    sequence.append(cv.cvtColor(cv.imread('save_gif.png'), cv.COLOR_BGR2RGB ))  \n",
        "\n",
        "  gif = ImageSequenceClip(sequence, fps=5)\n",
        "  gif.write_gif('conn' + str(num)+'.gif', fps=5)"
      ],
      "metadata": {
        "id": "bcYblI5XOsn7"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}