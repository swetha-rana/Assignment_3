{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "rnn_seq_to_seq.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyNncfqBzwp580Ujk3PG7V51",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/swetha-rana/Assignment_3/blob/main/rnn_seq_to_seq.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Below cells installs the necessary modules"
      ],
      "metadata": {
        "id": "gkuFi-ta8nvD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%capture\n",
        "!pip install wandb"
      ],
      "metadata": {
        "id": "O3i9fiJ38m3l"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Below cell imports the necessary modules"
      ],
      "metadata": {
        "id": "fs_zq4Y_8K03"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BME0keAv8FY4"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "import pandas as pd\n",
        "import wandb"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Below cell downloads the dataset and untars it"
      ],
      "metadata": {
        "id": "soB70qN69k2a"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!wget https://storage.googleapis.com/gresearch/dakshina/dakshina_dataset_v1.0.tar\n",
        "!tar -xvf dakshina_dataset_v1.0.tar"
      ],
      "metadata": {
        "id": "21JXJTj-8J-8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Data processing cell"
      ],
      "metadata": {
        "id": "pbjOLDTiBOdx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def data_preprocessing(path,ip_token=None,ip_len=None,output_token=None,output_len=None):\n",
        "  \n",
        "  ip_transcription= []\n",
        "  output_transcription= []\n",
        "  \n",
        "  df= pd.read_csv(path,names=[\"1\", \"2\",\"3\"],sep=\"\\t\").astype(str)\n",
        "  if ip_token is None:\n",
        "      df=df.sample(frac=1)\n",
        "  for index, row in df.iterrows():\n",
        "      ip_text=row['2']\n",
        "      op_text= row['1']\n",
        "      if ip_text=='</s>' or op_text =='</s>':\n",
        "        continue\n",
        "      op_text= \"\\t\" + op_text + \"\\n\"\n",
        "      ip_transcription.append(ip_text)\n",
        "      output_transcription.append(op_text)\n",
        "  \n",
        "  if ip_token is None:\n",
        "    ip_token= tf.keras.preprocessing.text.Tokenizer(filters='', char_level=True)\n",
        "    ip_token.fit_on_texts(ip_transcription)\n",
        "  input_text= ip_token.texts_to_sequences(ip_transcription)\n",
        "  input_text= tf.keras.preprocessing.sequence.pad_sequences(input_text,padding='post')\n",
        "\n",
        "  if output_token is None:\n",
        "    output_token= tf.keras.preprocessing.text.Tokenizer(filters='', char_level=True)\n",
        "    output_token.fit_on_texts(output_transcription)\n",
        "\n",
        "  output_text= output_token.texts_to_sequences(output_transcription)\n",
        "  output_text= tf.keras.preprocessing.sequence.pad_sequences(output_text,padding='post')\n",
        "\n",
        "  if ip_len is not None and output_len is not None:\n",
        "      input_text=tf.concat([input_text,tf.zeros((input_text.shape[0],ip_len-input_text.shape[1]))],axis=1)\n",
        "      output_text=tf.concat([output_text,tf.zeros((output_text.shape[0],output_len-output_text.shape[1]))],axis=1)\n",
        "\n",
        "  return input_text,ip_token,output_transcription,output_text,output_token"
      ],
      "metadata": {
        "id": "qBDjm53fBNJ8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_input_text,train_ip_token,train_output_transcription,train_output_text,train_output_token=data_preprocessing(\"/content/dakshina_dataset_v1.0/ta/lexicons/ta.translit.sampled.train.tsv\")\n",
        "\n",
        "val_input_text,val_ip_token,val_output_transcription,val_output_text,val_output_token=data_preprocessing(\"/content/dakshina_dataset_v1.0/ta/lexicons/ta.translit.sampled.dev.tsv\",input_tokenizer,input_tensor.shape[1],target_tokenizer,target_tensor.shape[1])\n",
        "\n",
        "test_input_text,test_ip_token,test_output_transcription,test_output_text,test_output_token=data_preprocessing(\"/content/dakshina_dataset_v1.0/ta/lexicons/ta.translit.sampled.test.tsv\",input_tokenizer,input_tensor.shape[1],target_tokenizer,target_tensor.shape[1])\n"
      ],
      "metadata": {
        "id": "mxMx8vYNCjIp"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}